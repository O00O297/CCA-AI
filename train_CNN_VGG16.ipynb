{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_CNN_VGG16",
      "provenance": [],
      "authorship_tag": "ABX9TyOcV2CaZ02zlOA9D1cGs13X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O00O297/CCA-AI/blob/master/train_CNN_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVNvnIOReSme"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch.utils.data as data\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "from os.path import isfile, join\n",
        "from os import walk\n",
        "from os import listdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7ZNt8jBem8E"
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "  print(\"Using CUDA\")\n",
        "else:\n",
        "  print(\"CPU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuNoriqvepyM"
      },
      "source": [
        "def default_loader(path):\n",
        "\treturn Image.open(path).convert('RGB')\n",
        "\n",
        "def default_flist_reader(flist,path):\n",
        "  imlist = []\n",
        "  # path = \"/content/drive/Shared drives/CCA-AI Slide/\"\n",
        "  with open(flist, 'r') as rf:\n",
        "    for line in rf.readlines():\n",
        "      impath, imlabel = line.strip().split()\n",
        "      dir = path+ \"/\" +impath\n",
        "      print(dir)\n",
        "      sub_dir = [x[2] for x in walk(dir)][0]\n",
        "      for img in sub_dir:\n",
        "        img_path =impath + \"/\" + img\n",
        "        imlist.append( (img_path, imlabel) )\n",
        "    print(imlist)\n",
        "  return imlist \n",
        "\n",
        "class ImageFilelist(data.Dataset):\n",
        "  def __init__(self, root, flist, transform=None, target_transform=None,\n",
        "               flist_reader=default_flist_reader, loader=default_loader):\n",
        "    self.root   = root\n",
        "    self.imlist = flist_reader(flist)\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.loader = loader\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    impath, target = self.imlist[index]\n",
        "    img = self.loader(os.path.join(self.root,impath))\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "    if self.target_transform is not None:\n",
        "      target = self.target_transform(target)\n",
        "\n",
        "    return img, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrBGCOmae5bG"
      },
      "source": [
        "train_loaders = torch.utils.data.DataLoader(\n",
        "    ImageFilelist(root=\"/content/drive/Shared drives/CCA-AI Slide\",\n",
        "                  flist=\"/content/drive/Shared drives/CCA-AI Slide/filepath_train.txt\",\n",
        "                  transform=transforms.Compose(\n",
        "        [transforms.Resize(256),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(), \n",
        "        ])),\n",
        "        batch_size=8, shuffle=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "val_loaders = torch.utils.data.DataLoader(\n",
        "    ImageFilelist(root=\"/content/drive/Shared drives/CCA-AI Slide\",\n",
        "                  flist=\"/content/drive/Shared drives/CCA-AI Slide/filepath_val.txt\",\n",
        "                  transform=transforms.Compose(\n",
        "        [transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(), \n",
        "        ])),\n",
        "        batch_size=8, shuffle=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "test_loaders = torch.utils.data.DataLoader(\n",
        "    ImageFilelist(root=\"/content/drive/Shared drives/CCA-AI Slide\",\n",
        "                  flist=\"/content/drive/Shared drives/CCA-AI Slide/filepath_test.txt\",\n",
        "                  transform=transforms.Compose(\n",
        "        [transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(), \n",
        "        ])),\n",
        "        batch_size=8, shuffle=False,\n",
        "        num_workers=4\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1aM5F3ne9zM"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "def show_databatch(inputs, classes):\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    imshow(out, title=[x for x in classes])\n",
        "\n",
        "inputs, classes = next(iter(val_loaders))\n",
        "show_databatch(inputs[0], classes[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukr7scvhe9sW"
      },
      "source": [
        "# vgg16 = models.vgg16_bn()\n",
        "vgg16 = models.vgg16_bn(pretrained=False,num_classes=3)\n",
        "# vgg16.load_state_dict(torch.load(\"/content/drive/Shared drives/CCA-AI Slide/Dataset/Model/VGG/vgg16_bn.pth\"))\n",
        "\n",
        "print(vgg16.classifier[6].out_features) # 1000 \n",
        "\n",
        "\n",
        "# Freeze training for all layers\n",
        "for param in vgg16.features.parameters():\n",
        "    param.require_grad = False\n",
        "\n",
        "# Newly created modules have require_grad=True by default\n",
        "num_features = vgg16.classifier[6].in_features\n",
        "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
        "features.extend([nn.Linear(num_features, 3)]) # Add our layer with 4 outputs\n",
        "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "print(vgg16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-jHeeCyfMuO"
      },
      "source": [
        "if use_gpu:\n",
        "    vgg16.cuda() #.cuda() will move everything to the GPU side\n",
        "    \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjFaIlEDfPam"
      },
      "source": [
        "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    avg_loss_val = 0\n",
        "    avg_acc_val = 0\n",
        "    \n",
        "    train_batches = len(train_loaders)\n",
        "    val_batches = len(val_loaders)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        loss_train = 0\n",
        "        loss_val = 0\n",
        "        acc_train = 0\n",
        "        acc_val = 0\n",
        "        \n",
        "        vgg.train(True)\n",
        "        \n",
        "        for i, (data) in enumerate(train_loaders):\n",
        "            if i % 100 == 0:\n",
        "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
        "                \n",
        "            # Use half training dataset\n",
        "            if i >= train_batches / 2:\n",
        "                break\n",
        "                \n",
        "            inputs, labels = data\n",
        "            inputs, labels = np.asarray(inputs, dtype = np.float32), np.asarray(labels, dtype = np.int64)\n",
        "            inputs, labels = torch.from_numpy(inputs), torch.from_numpy(labels)\n",
        "            \n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # loss_train += loss.data[0]\n",
        "            loss_train += loss.data\n",
        "            acc_train += torch.sum(preds == labels.data)\n",
        "            \n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        print()\n",
        "        # * 2 as we only used half of the dataset\n",
        "        avg_loss = loss_train * 2 / float(len(train_loaders))\n",
        "        avg_acc = acc_train * 2 / float(len(train_loaders))\n",
        "        \n",
        "        vgg.train(False)\n",
        "        vgg.eval()\n",
        "            \n",
        "        for i, (data) in enumerate(val_loaders):\n",
        "            if i % 100 == 0:\n",
        "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
        "                # print(\"Val\")\n",
        "                \n",
        "            inputs, labels = data\n",
        "            inputs, labels = np.asarray(inputs, dtype = np.float32), np.asarray(labels, dtype = np.int64)\n",
        "            inputs, labels = torch.from_numpy(inputs), torch.from_numpy(labels)\n",
        "            \n",
        "            if use_gpu:\n",
        "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
        "            else:\n",
        "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = vgg(inputs)\n",
        "            \n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # loss_val += loss.data[0]\n",
        "            loss_val += loss.data\n",
        "            acc_val += torch.sum(preds == labels.data)\n",
        "            \n",
        "            del inputs, labels, outputs, preds\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        avg_loss_val = loss_val / float(len(train_loaders))\n",
        "        avg_acc_val = acc_val / float(len(val_loaders))\n",
        "        \n",
        "        print()\n",
        "        print(\"Epoch {} result: \".format(epoch))\n",
        "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
        "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
        "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
        "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
        "        print('-' * 10)\n",
        "        print()\n",
        "        \n",
        "        if avg_acc_val > best_acc:\n",
        "            best_acc = avg_acc_val\n",
        "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
        "        \n",
        "    elapsed_time = time.time() - since\n",
        "    print()\n",
        "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
        "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
        "    \n",
        "    vgg.load_state_dict(best_model_wts)\n",
        "    return vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoSwng8UfUMA"
      },
      "source": [
        "vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\n",
        "status = torch.save(vgg16.state_dict(), '/content/drive/Shared drives/CCA-AI Slide/Slide_preprocess/model3class.pt')\n",
        "print(status)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}